---
title: "FaceNet: A Unified Embedding for Face Recognition and Clustering"
layout: post
date: 2018-03-29
headerImage: false
tag:
- face-net
- embedding
- face-verification
- face-recognition
- face-clustering
category: blog
author: roomylee
---

- Paper Link: <https://arxiv.org/abs/1503.03832>
- Author
  - Florian Schroff (Google)
  - Dmitry Kalenichenko (Google)
  - James Philbin (Google)
- Published at
  - CVPR 2015

---

## Abstract

- Implementing face verification and recognition efficiently at scale presents serious challenges to current approaches.
  - ➤ 크기에 맞게 효율적으로 얼굴 확인 및 인식을 구현하는 것은 현재의 접근법으로 보았을 때 상당히 도전적인 과제이다.
- In this paper, we present *FaceNet*, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity.
  - ➤ 이 논문에서 우리는 *FaceNet*을 소개할 것이다. *FaceNet*은 유클리디안 공간에 얼굴 이미지를 매핑되는 좌표를 학습시키고, 매핑된 좌표들의 거리는 얼굴의 유사도를 의미하게 된다.
- Our method uses a deep CNN trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches.
  - ➤ 우리는 이전 연구처럼 중간에 bottleneck layer를 사용하기 보다 직접적으로 embedding layer를 최적화하도록 CNN을 학습시켰다.
- On the widely used *Labeled Faces in the Wild (LFW)* dataset and *YouTube Faces* DB, our system achieves a accuracy better than the previous best published result.
  - ➤ 우리의 시스템은 *LFW* dataset과 *YouTube Faces* DB에 대해서 이전 최고 기록보다 더 나은 정확도를 얻었다.

## 1. Introduction

- In this paper we present a unified system for ➤ 우리는 아래의 task를 위한 통합 시스템을 제안한다.
  1. face verification (is this the same person) ➤ 같은 사람인가?
  2. face recognition (who is this person) ➤ 이 사람은 누구인가?
  3. face clustering (find common people among these faces) ➤ 공통된 사람을 찾아라(묶어라)

 ![facenet](https://user-images.githubusercontent.com/15166794/35256631-0fd0f62a-0038-11e8-85e4-67dd005ab981.png){: .center}

- The network(CNN) is trained such that the squared L2 distances in the embedding space directly correspond to face similarity: faces of the same person have small distances and faces of distinct people have large distances.
  - ➤ 네트워크는 embedding space에서 squared L2 distance가 얼굴 유사도에 대응하도록 학습된다. 같은 사람의 얼굴의 경우 거리가 작고 다른 사람은 큰 거리를 갖는다.

- Once this embedding has been produced, ➤ 한번 embedding이 학습되고 나면,
  1. face verification simply involves thresholding the distance between the two embeddings
     - ➤ face verification은 distance에 대한 thresholding을 통해 해결할 수 있다.
  2. face recognition becomes a k-NN classification problem
     - ➤ face recognition은 k-NN 분류 문제로 풀 수 있다.
  3. face clustering can be achieved using off-the-shelf techniques such as k-means or agglomerative clustering
     - ➤ face clustering은 거리 k-means 같은 off-the-shelf 테크닉을 사용하여 풀 수 있다.

- Previous face recognition approaches based on deep networks take an intermediate bottleneck layer as a representation.
  - ➤ 이전에 deep networks 기반의 face recognition 연구는 representation(embeddings)로 중간에 있는 bottleneck layer를 사용했다.
- The downsides of this approach are its indirectness and its inefficiency. ➤ 이런 접근의 단점은 비직접성(간접성)과 비효율성이다.
  - one has to hope that the bottleneck representation generalizes well to new faces
    - ➤ 새로운 얼굴에 대해서 bottleneck representation이 잘 일반화하여 판단해야 한다. (새로운 얼굴을 잘 인식하지 못 할 가능성이 크다.)
  - representation size per face is usually very large (1000s of dimensions)
    - ➤ 얼굴에 대한 representation size가 보통 너무 크다.

- Incontrast, *FaceNet* directly trains its output to be a compct 128-D embedding using a triplet based loss function based on LMNN.
  - ➤ 반면, *FaceNet*은 LMNN에서의 triplet기반의 loss function을 사용하여 직접적으로 output이 128-D embedding이 되도록 학습을 시킨다.
- Our triplets consist of two matching face thumbnails and a non-matching face thumbnail and the loss aims to separate the positive pair from the negative by a distance margin.
  - ➤ triplets은 2개의 matching face와 1개의 non-matching face로 구성되고 loss는 positive pair를 negative로부터 거리 상으로 떼어내는 것을 목적으로 한다.

- Choosing which triplets to use turns out to be very important for achieving good performance and, inspired by curriculum learning, we present a novel online negative exemplar mining strategy which ensures consistently increasing difficulty of triplets as the network trains.
  - ➤ triplets을 선정하는 것이 좋은 성능을 얻는데 있어서 매우 중요하다. 우리는 curriculum learning에서 영감을 받아 네트워크 학습에 있어서 triplet의 어려움을 지속적으로 증가시키는 새로운 online negative exemplar mining strategy을 제시한다.

## 2. Related Work

- skip...

## 3. Method

![architecture_triplet](https://user-images.githubusercontent.com/15166794/35470350-3d688b74-038b-11e8-992b-2ed6db6f6a5b.png)

- We employ the triplet loss that directly reflects what we want to achieve in face verification, recognition and clustering.
  - ➤ 우리는 triplet loss를 이용하여 face verification, recognition and clustering에서 성취하길 원한다.
- we strive for an embedding f(x), from an image x into a feature space <img src="https://latex.codecogs.com/svg.latex?R^d"/>, such that the squared distance between all faces, independent of imaging conditions, of the same identity is small, whereas the squared distance between a pair of face images from different identities is large.
  - ➤ f(x)라는 임베딩 함수를 얻고자 한다. 어떤 이미지 x로 부터 feature space <img src="https://latex.codecogs.com/svg.latex?R^d"/>를 얻는 것이다. 같은 identity pair의 경우에는 feature space에서의 distance가 작고 다른 identity pair의 경우에는 distance가 커지게 임베딩한다.

### 3.1. Triplet Loss

- Here we want to ensure that an image <img src="https://latex.codecogs.com/svg.latex?x_i^a"/> (anchor) of a specific person is closer to all other images <img src="https://latex.codecogs.com/svg.latex?x_i^p"/> (positive) of the same person than it is to any image <img src="https://latex.codecogs.com/svg.latex?x_i^n"/> (negative) of any other person. This is visualized in Figure 3.
  - ➤ 특정 인물을 anchor로 두고 이와 같은 사람들인 positive를 다른 사람인 negative보다 거리가 가깝도록 한다. 시각적으로 나타내면 Figure 3와 같다.

<img src="https://latex.codecogs.com/svg.latex?||f(x_i^a)-f(x_i^p)||_2^2+\alpha<||f(x_i^a)-f(x_i^n)||_2^2"/>

- where α is a margin that is enforced between positive and negative pairs
  - ➤ α는 positive과 negative 간의 margin을 의미한다. 즉, anchor에 대해 negative는 positive보다 최소 α 이상 떨어져 있도록 하는 것이다.
- The loss that is being minimized is then

<img src="https://latex.codecogs.com/svg.latex?L=\sum_i^N{[||f(x_i^a)-f(x_i^p)||_2^2-||f(x_i^a)-f(x_i^n)||_2^2+\alpha]_+}"/>

- <img src="https://latex.codecogs.com/svg.latex?[x]_+=max(0,x)"/>
- <img src="https://latex.codecogs.com/svg.latex?||f(x)||_2=1"/>
- <img src="https://latex.codecogs.com/svg.latex?\alpha=0.2"/>

### 3.2. Triplet Selection

- Given <img src="https://latex.codecogs.com/svg.latex?x_i^a"/>, we want to select an <img src="https://latex.codecogs.com/svg.latex?x_i^p"/> (hard positive) such that <img src="https://latex.codecogs.com/svg.latex?argmax_{x_i^p}{||f(x_i^a)-f(x_i^p)||_2^2}"/> and similarly <img src="https://latex.codecogs.com/svg.latex?x_i^n"/> (hard negative) such that <img src="https://latex.codecogs.com/svg.latex?argmin_{x_i^n}{||f(x_i^a)-f(x_i^n)||_2^2}"/>.
  - ➤ anchor가 주어졌을 때 hard positive(positive 중에 가장 먼 것)랑 hard negative(negative 중에 가장 가까운 것)를 구하길 원한다.
- But, it is infeasible to compute the argmin and argmax across the whole training set.
  - ➤ 하지만 모든 학습 데이터에 대해서 argmin, argmax를 하는 것은 현실적으로 불가능하다.
- we use large mini-batches in the order of a few thousand exemplars and only compute the argmin and argmax within a mini-batch.
  - ➤ 그래서 mini-batch를 사용해서 하나의 batch에 해당하는 약 수천 개의 샘플에 대해서만 argmin, argmax를 계산하도록 하였다.
- Instead of picking the hardest positive, we use all anchor-positive pairs in a mini-batch while still selecting the hard negatives.
  - ➤ hardest positive를 고르는 대신 positive 전체를 다 사용해서 학습하였고, 반면 negative의 경우는 그대로 hard negative를 고르도록 하였다.
- but we found in practice that the all anchor-positive method was more stable and converged slightly faster at the beginning of training.
  - ➤ 꼭 hard-positive을 안쓰고 모든 positive를 썼을 때 더 안정적이고 초반에 더 빠르게 수렴하는 것을 경험적으로 알 수 있었다.

- Selecting the hardest negatives can in practice lead to bad local minima early on in training, specifically it can result in a collapsed model (i.e. f(x) = 0).
  - ➤ hardest negative를 선택하는 것은 local minima의 위험이 있다.
- In order to mitigate this, it helps to select <img src="https://latex.codecogs.com/svg.latex?x_i^n"/> such that
  - ➤ 이를 완화시키기위해, 아래의 식으로 negative를 구한다.

 <img src="https://latex.codecogs.com/svg.latex?||f(x_i^a)-f(x_i^p)||_2^2<||f(x_i^a)-f(x_i^n)||_2^2"/>

- We call these negative exemplars semi-hard, as they are further away from the anchor than the positive exemplar, but still hard because the squared distance is close to the anchor-positive distance.
  - ➤ 이렇게 구한 negative 샘플을 semi-hard라고 한다. positive보다 먼 negative를 구하는 것인데 이 경우 선택된 negative가 positive랑 가깝기 때문에 hard로 볼 수 있다.

### 3.3. Deep Convolutional Networks

![convnet](https://user-images.githubusercontent.com/15166794/35526429-b1cba772-056a-11e8-95c8-837904c3e981.png)
